{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxv7c/tOFssggIFA1m2A6J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrashtiDholariya/lstm_text_generator/blob/main/lstm_text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J3HWgoLD9Y73",
        "outputId": "7cd70492-aa34-4705-92de-39c06a03d09b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U numpy==2.0.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ob6rW07c-AYi",
        "outputId": "3dd21e43-e8d7-44f6-e491-e34ea46527f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==2.0.2 in /usr/local/lib/python3.12/dist-packages (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n"
      ],
      "metadata": {
        "id": "NxqU7UFh7j9j"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cJs-Cm26E4D",
        "outputId": "9feee590-2803-45db-f5b4-f429aa81e39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters (raw): 5166764\n",
            "Sample text:\n",
            " the project gutenberg ebook of the complete works of william shakespeare\n",
            "    \n",
            "this ebook is for the use of anyone anywhere in the united states and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. you may copy it, give it away or re-use it under the terms\n",
            "of the p\n"
          ]
        }
      ],
      "source": [
        "# Load shakespeare text data set\n",
        "with open(\"/content/data/shakespeare.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read().lower()\n",
        "\n",
        "print(\"Total characters (raw):\", len(text))\n",
        "print(\"Sample text:\\n\", text[:300])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean text data\n",
        "# Keep only lowercase letters and spaces\n",
        "text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "\n",
        "text = text[:300000]\n",
        "\n",
        "print(\"\\nAfter cleaning:\")\n",
        "print(\"Total characters (cleaned):\", len(text))\n",
        "print(text[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIng1G017gWc",
        "outputId": "3e1971f4-072d-49a7-cc2c-f9e4977c22bf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After cleaning:\n",
            "Total characters (cleaned): 300000\n",
            "the project gutenberg ebook of the complete works of william shakespeare\n",
            "    \n",
            "this ebook is for the use of anyone anywhere in the united states and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever you may copy it give it away or reuse it under the terms\n",
            "of the proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Character-level tokenization\n",
        "# Create sorted list of unique characters\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"\\nUnique characters:\", len(chars))\n",
        "\n",
        "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
        "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
        "\n",
        "encoded_text = np.array([char_to_idx[c] for c in text])\n",
        "print(\"Encoded sample:\", encoded_text[:50])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5lZq7Kr7q6s",
        "outputId": "f2923053-c810-4783-94dd-ecaf8b8dcbd5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unique characters: 28\n",
            "Encoded sample: [21  9  6  1 17 19 16 11  6  4 21  1  8 22 21  6 15  3  6 19  8  1  6  3\n",
            " 16 16 12  1 16  7  1 21  9  6  1  4 16 14 17 13  6 21  6  1 24 16 19 12\n",
            " 20  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input-output sequences\n",
        "SEQ_LENGTH = 40\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(len(encoded_text) - SEQ_LENGTH):\n",
        "    X.append(encoded_text[i:i + SEQ_LENGTH])\n",
        "    y.append(encoded_text[i + SEQ_LENGTH])\n",
        "\n",
        "X = np.array(X)\n",
        "y = to_categorical(y, num_classes=len(chars))\n",
        "\n",
        "print(\"\\nX shape:\", X.shape)\n",
        "print(\"Y shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omidZ7Kx8OlS",
        "outputId": "06ef770c-7e60-465d-8899-0606274cddbf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X shape: (299960, 40)\n",
            "Y shape: (299960, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    Input(shape=(SEQ_LENGTH,)),\n",
        "    Embedding(input_dim=len(chars), output_dim=50),\n",
        "    LSTM(128),\n",
        "    Dense(len(chars), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\"\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "5Ion688OAAFh",
        "outputId": "06d63277-25ee-411a-9aa6-d2b08de756fc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │         \u001b[38;5;34m1,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m91,648\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m3,612\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m96,660\u001b[0m (377.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,660</span> (377.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m96,660\u001b[0m (377.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,660</span> (377.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X, y,\n",
        "    batch_size=128,\n",
        "    epochs=20,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BFhRxNgBEqm",
        "outputId": "0ac81bdf-b3fa-4e19-cdfd-3821bccff364"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 2.4091 - val_loss: 1.9772\n",
            "Epoch 2/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.8325 - val_loss: 1.7743\n",
            "Epoch 3/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.6789 - val_loss: 1.6707\n",
            "Epoch 4/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 1.5823 - val_loss: 1.6162\n",
            "Epoch 5/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 1.5261 - val_loss: 1.5759\n",
            "Epoch 6/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.4908 - val_loss: 1.5554\n",
            "Epoch 7/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.4569 - val_loss: 1.5351\n",
            "Epoch 8/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.4295 - val_loss: 1.5186\n",
            "Epoch 9/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.4091 - val_loss: 1.5081\n",
            "Epoch 10/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 1.3883 - val_loss: 1.5021\n",
            "Epoch 11/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.3814 - val_loss: 1.4967\n",
            "Epoch 12/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 1.3602 - val_loss: 1.4878\n",
            "Epoch 13/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 1.3484 - val_loss: 1.4847\n",
            "Epoch 14/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.3384 - val_loss: 1.4903\n",
            "Epoch 15/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.3290 - val_loss: 1.4844\n",
            "Epoch 16/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.3157 - val_loss: 1.4858\n",
            "Epoch 17/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 1.3103 - val_loss: 1.4821\n",
            "Epoch 18/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.2994 - val_loss: 1.4782\n",
            "Epoch 19/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.2944 - val_loss: 1.4802\n",
            "Epoch 20/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.2936 - val_loss: 1.4802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78ecb4ce5d90>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_with_temperature(preds, temperature=0.8):\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds + 1e-8) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    return np.random.choice(len(preds), p=preds)"
      ],
      "metadata": {
        "id": "oXkAl43xk-Te"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text generation\n",
        "def generate_text(seed, length=300, temperature=0.8):\n",
        "    seed = seed.lower()\n",
        "    result = seed\n",
        "\n",
        "    for _ in range(length):\n",
        "        seq = [char_to_idx.get(c, 0) for c in seed]\n",
        "        seq = pad_sequences([seq], maxlen=SEQ_LENGTH)\n",
        "\n",
        "        prediction = model.predict(seq, verbose=0)[0]\n",
        "        next_index = sample_with_temperature(prediction, temperature)\n",
        "        next_char = idx_to_char[next_index]\n",
        "\n",
        "        result += next_char\n",
        "        seed = seed[1:] + next_char\n",
        "\n",
        "    return result\n",
        "\n",
        "user_seed = input(\"\\nEnter starting text: \").lower()\n",
        "\n",
        "if len(user_seed) < SEQ_LENGTH:\n",
        "    user_seed = user_seed.rjust(SEQ_LENGTH)\n",
        "\n",
        "gen_length = int(input(\"Enter number of characters to generate: \"))\n",
        "\n",
        "output = generate_text(user_seed, gen_length, temperature=0.8)\n",
        "\n",
        "print(\"\\nGenerated Text:\\n\")\n",
        "print(output)\n",
        "\n",
        "with open(\"sample_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"User Input:\\n\")\n",
        "    f.write(user_seed.strip() + \"\\n\\n\")\n",
        "    f.write(\"Generated Output:\\n\")\n",
        "    f.write(output)\n",
        "\n",
        "print(\"\\nSaved to sample_output.txt successfully\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeEGgPu5DJgx",
        "outputId": "25ce4a32-ad3e-42b1-8476-a1caffed7028"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter starting text: shall i compare thee\n",
            "Enter number of characters to generate: 500\n",
            "\n",
            "GENERATED TEXT:\n",
            "\n",
            "                    shall i compare thee a many and they may concribla and many great\n",
            "for thou dost is not be of threat that dreach\n",
            "the thine play deing me to be doth true still\n",
            "scene xii\n",
            "a passive a cloud not had\n",
            "\n",
            "\n",
            "                    \n",
            "\n",
            "let take a creasure issued i believe beare\n",
            "that is cannot since see a room in the redument\n",
            "whither doth heavens stands\n",
            "\n",
            "bertram\n",
            "his hearts and dispactions bade but i will be present better touse\n",
            "\n",
            "first lord\n",
            "o thank you are that body down to thee\n",
            "the post that with my marry thou being more more\n",
            "is it o\n",
            "\n",
            "Saved successfully to sample_output.txt\n"
          ]
        }
      ]
    }
  ]
}